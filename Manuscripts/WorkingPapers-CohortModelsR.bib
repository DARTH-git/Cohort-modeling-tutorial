Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Alarid-Escudero2017b,
abstract = {Evidence about treatment efficacy and long-term toxicities for adjuvant chemotherapy in patients with early- stage breast cancer is often presented in different formats and studies. This leads to challenges for patients and their physi- cians to adequately weigh the trade-offs between effectiveness and long-term cardiac toxicity when making decisions about adjuvant chemotherapy. We used a decision-analytic framework to quantify these trade-offs by combining the available evi- dence into a single, comparable metric. We developed a Markov model to simulate a hypothetical cohort of newly diag- nosed breast cancer patients under three scenarios: no treatment, anthracycline (AC)-based adjuvant chemotherapy (more effective but also more cardiotoxic), and non-AC-based adjuvant chemotherapy. We derived the model parameters from medical literature (e.g., clinical trials). Our primary outcome is 10-year mortality, and other metrics such as cause of death; life years (LYs) and quality-adjusted LYs over 10 years were evaluated in sensitivity analysis. For 55-year-old women with a 10-year risk of metastatic recurrence {\textless}12.5{\%} no chemotherapy resulted in the preferred strategy. In general, non- AC-based adjuvant chemotherapy resulted in lower 10-year mortality than AC-based chemotherapy. Patients with low risk of metastatic recurrence are better off without adjuvant chemotherapy regardless of the outcome considered (i.e., the risks of cardiac toxicity from chemotherapy outweighed the benefits). Trade-offs between effectiveness and induced cardiac toxi- city impact health outcomes. The choice of adjuvant treatment must consider the patient's risk of distant recurrence and the quality of life associated with different health outcomes.},
author = {Alarid-Escudero, Fernando and Blaes, Anne H. and Kuntz, Karen M.},
doi = {10.1111/tbj.12757},
file = {:Users/fae/Documents/Mendeley Desktop/Alarid-Escudero, Blaes, Kuntz/The Breast Journal/Alarid-Escudero, Blaes, Kuntz - 2017 - Trade-offs Between Efficacy and Cardiac Toxicity of Adjuvant Chemotherapy in Early-Stage Breast C.pdf:pdf;:Users/fae/Documents/Mendeley Desktop/Alarid-Escudero, Blaes, Kuntz/The Breast Journal/Alarid-Escudero, Blaes, Kuntz - 2017 - Trade-offs Between Efficacy and Cardiac Toxicity of Adjuvant Chemotherapy in Early-Stage Breas(2).pdf:pdf},
issn = {1075122X},
journal = {The Breast Journal},
keywords = {adjuvant chemotherapy,breast cancer,cardiac toxicity,decision-analytic model,markov model},
number = {4},
pages = {401--409},
title = {{Trade-offs Between Efficacy and Cardiac Toxicity of Adjuvant Chemotherapy in Early-Stage Breast Cancer Patients: Do Competing Risks Matter?}},
url = {http://doi.wiley.com/10.1111/tbj.12757},
volume = {23},
year = {2017}
}
@article{Filipovic-Pierucci2017,
abstract = {Health economic evaluation studies are widely used in public health to assess health strategies in terms of their cost-effectiveness and inform public policies. We developed an R package for Markov models implementing most of the modelling and reporting features described in reference textbooks and guidelines: deterministic and probabilistic sensitivity analysis, heterogeneity analysis, time dependency on state-time and model-time (semi-Markov and non-homogeneous Markov models), etc. In this paper we illustrate the features of heemod by building and analysing an example Markov model. We then explain the design and the underlying implementation of the package.},
archivePrefix = {arXiv},
arxivId = {1702.03252},
author = {Filipovi{\'{c}}-Pierucci, Antoine and Zarca, Kevin and Durand-Zaleski, Isabelle},
eprint = {1702.03252},
file = {:Users/fae/Documents/Mendeley Desktop/Filipovi{\'{c}}-Pierucci, Zarca, Durand-Zaleski/arXiv1702.03252v1/Filipovi{\'{c}}-Pierucci, Zarca, Durand-Zaleski - 2017 - Markov Models for Health Economic Evaluation The R Package heemod.pdf:pdf},
journal = {arXiv:1702.03252v1},
keywords = {health economic evaluation,markov models,r},
pages = {30},
title = {{Markov Models for Health Economic Evaluation: The R Package heemod}},
url = {http://arxiv.org/abs/1702.03252},
volume = {April},
year = {2017}
}
@misc{RCoreTeam2019,
address = {Vienna, Austria},
author = {{R Core Team}},
publisher = {R Foundation for Statistical Computing},
title = {{R: A Language and Environment for Statistical Computing}},
url = {http://www.r-project.org/},
year = {2019}
}
@article{Snowsill2019a,
author = {Snowsill, Tristan},
file = {:Users/fae/Documents/Mendeley Desktop/Snowsill/Medical Decision Making/Snowsill - 2019 - A New Method for Model-Based Health Economic Evaluation Utilizing and Extending Moment-Generating Functions. Appendice.pdf:pdf},
journal = {Medical Decision Making},
number = {5},
title = {{A New Method for Model-Based Health Economic Evaluation Utilizing and Extending Moment-Generating Functions. Appendices 1-8}},
volume = {39},
year = {2019}
}
@article{Hollman2017,
abstract = {The volume and technical complexity of both academic and commercial research using decision analytic modelling has increased rapidly over the last two decades. The range of software programs used for their implementation has also increased, but it remains true that a small number of programs account for the vast majority of cost-effectiveness modelling work. We report a comparison of four software programs: TreeAge Pro, Microsoft Excel, R and MATLAB. Our focus is on software commonly used for building Markov models and decision trees to conduct cohort simulations, given their predominance in the published literature around cost-effectiveness modelling. Our comparison uses three qualitative criteria as proposed by Eddy et al.: “transparency and validation”, “learning curve” and “capability”. In addition, we introduce the quantitative criterion of processing speed. We also consider the cost of each program to academic users and commercial users. We rank the programs based on each of these criteria. We find that, whilst Microsoft Excel and TreeAge Pro are good programs for educational purposes and for producing the types of analyses typically required by health technology assessment agencies, the efficiency and transparency advantages of programming languages such as MATLAB and R become increasingly valuable when more complex analyses are required.},
author = {Hollman, Chase and Paulden, Mike and Pechlivanoglou, Petros and McCabe, Christopher},
doi = {10.1007/s40273-017-0510-8},
file = {:Users/fae/Documents/Mendeley Desktop/Hollman et al/PharmacoEconomics/Hollman et al. - 2017 - A Comparison of Four Software Programs for Implementing Decision Analytic Cost-Effectiveness Models.pdf:pdf},
issn = {11792027},
journal = {PharmacoEconomics},
number = {8},
pages = {817--830},
pmid = {28488257},
publisher = {Springer International Publishing},
title = {{A Comparison of Four Software Programs for Implementing Decision Analytic Cost-Effectiveness Models}},
volume = {35},
year = {2017}
}
@article{Sasieni1999,
abstract = {The authors propose the use of two new standardized measures of risk, the standardized lifetime risk and the standardized number of years of life lost. These measures maintain the advantages of standardized rates but are more readily understood without special training. In this paper, standardizing weights based on 1992 data from England and Wales are provided, and the new measures are illustrated with a variety of examples. The new standardized rates are useful for examining trends over time; for comparing the impact of various diseases on public health; and for comparing rates of a given disease in several different countries. The authors think it is far more informative to say that 41 out of every 1,000 women die of breast cancer than to say that the standardized mortality rate is 51 per 100,000 women per year.},
author = {Sasieni, P D and Adams, J},
file = {:Users/fae/Documents/Mendeley Desktop/Sasieni, Adams/American journal of epidemiology/Sasieni, Adams - 1999 - Standardized lifetime risk.pdf:pdf},
issn = {0002-9262},
journal = {American journal of epidemiology},
keywords = {Female,Humans,Life Expectancy,Lifetime risk,Male,Models,Mortality,Risk Assessment,Statistical,Vital Statistics},
mendeley-tags = {Lifetime risk},
number = {9},
pages = {869--75},
pmid = {10221324},
title = {{Standardized lifetime risk.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10221324},
volume = {149},
year = {1999}
}
@article{Iskandar2018b,
author = {Iskandar, Rowan},
file = {:Users/fae/Documents/Mendeley Desktop/Iskandar/PLOS ONE/Iskandar - 2018 - A theoretical foundation of state-transition cohort models in health decision analysis. Supplement.pdf:pdf},
journal = {PLOS ONE},
number = {3},
title = {{A theoretical foundation of state-transition cohort models in health decision analysis. Supplement}},
volume = {12},
year = {2018}
}
@article{Sonnenberg1993,
author = {Sonnenberg, F. A. and Beck, J. R.},
doi = {10.1177/0272989X9301300409},
file = {:Users/fae/Documents/Mendeley Desktop/Sonnenberg, Beck/Medical Decision Making/Sonnenberg, Beck - 1993 - Markov models in medical decision making A practical guide.pdf:pdf},
issn = {0272-989X},
journal = {Medical Decision Making},
keywords = {Markov models,Markov-cycle decision tree,decision making.},
number = {4},
pages = {322--338},
title = {{Markov models in medical decision making: A practical guide}},
url = {http://mdm.sagepub.com/cgi/doi/10.1177/0272989X9301300409},
volume = {13},
year = {1993}
}
@article{Siebert2012c,
author = {Siebert, U. and Alagoz, O. and Bayoumi, A. M. and Jahn, B. and Owens, D. K. and Cohen, D. J. and Kuntz, K. M.},
doi = {10.1177/0272989X12455463},
file = {:Users/fae/Documents/Mendeley Desktop/Siebert et al/Medical Decision Making/Siebert et al. - 2012 - State-Transition Modeling A Report of the ISPOR-SMDM Modeling Good Research Practices Task Force-3.pdf:pdf},
issn = {0272-989X},
journal = {Medical Decision Making},
keywords = {Best practices,Guidelines,Markov models,decision-analytic modeling,guidelines,state-transition modeling},
mendeley-tags = {Best practices,Guidelines},
number = {5},
pages = {690--700},
title = {{State-Transition Modeling: A Report of the ISPOR-SMDM Modeling Good Research Practices Task Force-3}},
url = {http://mdm.sagepub.com/cgi/doi/10.1177/0272989X12455463},
volume = {32},
year = {2012}
}
@article{Suijkerbuijk2018,
abstract = {Background Chronic infection with hepatitis B or C virus (HBV/HCV) can progress to cirrhosis, liver cancer, and even death. In a low endemic country as the Netherlands, migrants are a key risk group and could benefit from early diagnosis and antiviral treatment. We assessed the cost-effectiveness of screening foreign-born migrants for chronic HBV and/or HCV using a societal perspective. Methods The cost-effectiveness was evaluated using a Markov model. Estimates on prevalence, screening programme costs, participation and treatment uptake, transition probabilities, healthcare costs, productivity losses and utilities were derived from the literature. The cost per Quality Adjusted Life Year (QALY) gained was estimated and sensitivity analyses were performed. Results For most migrant groups with an expected high number of chronically infected cases in the Netherlands combined screening is cost-effective, with incremental cost-effectiveness ratios (ICERs) ranging from €4,962/QALY gained for migrants originating from the Former Soviet Union and Vietnam to €9,375/QALY gained for Polish migrants. HBV and HCV screening proved to be cost-effective for migrants from countries with chronic HBV or HCV prevalence of 0.41{\%} and 0.22{\%}, with ICERs below the Dutch cost-effectiveness reference value of €20,000/QALY gained. Sensitivity analysis showed that treatment costs influenced the ICER for both infections. Conclusions For most migrant populations in a low-endemic country offering combined HBV and HCV screening is cost-effective. Implementation of targeted HBV and HCV screening programmes to increase early diagnosis and treatment is important to reduce the burden of chronic hepatitis B and C among migrants.},
author = {Suijkerbuijk, Anita W.M. and {Van Hoek}, Albert Jan and Koopsen, Jelle and {De Man}, Robert A. and Mangen, Marie Josee J. and {De Melker}, Hester E. and Polder, Johan J. and {De Wit}, G. Ardine and Veldhuijzen, Irene K.},
doi = {10.1371/journal.pone.0207037},
file = {:Users/fae/Documents/Mendeley Desktop/Suijkerbuijk et al/PLoS ONE/Suijkerbuijk et al. - 2018 - Cost-effectiveness of screening for chronic hepatitis B and C among migrant populations in a low endemic co.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
number = {11},
pages = {1--16},
pmid = {30408079},
title = {{Cost-effectiveness of screening for chronic hepatitis B and C among migrant populations in a low endemic country}},
volume = {13},
year = {2018}
}
@article{Alarid-Escudero2019b,
author = {Alarid-Escudero, Fernando and Enns, Eva A. and Kuntz, Karen M. and Michaud, Tzeyu L. and Jalal, Hawre},
doi = {10.1016/j.jval.2019.02.008},
file = {:Users/fae/Documents/Mendeley Desktop/Alarid-Escudero et al/Value in Health/Alarid-Escudero et al. - 2019 - Time Traveling Is Just Too Dangerous But Some Methods Are Worth Revisiting The Advantages of Expected L.docx:docx;:Users/fae/Documents/Mendeley Desktop/Alarid-Escudero et al/Value in Health/Alarid-Escudero et al. - 2019 - Time Traveling Is Just Too Dangerous But Some Methods Are Worth Revisiting The Advantages of Expected Lo.pdf:pdf},
journal = {Value in Health},
number = {5},
title = {{"Time Traveling Is Just Too Dangerous" But Some Methods Are Worth Revisiting: The Advantages of Expected Loss Curves Over Cost-Effectiveness Acceptability Curves and Frontier. Supplement}},
volume = {22},
year = {2019}
}
@article{Arias2017,
abstract = {Objectives—This report presents complete period life tables for the United States by race, Hispanic origin, and sex, based on age-specific death rates in 2014. Methods—Data used to prepare the 2014 life tables are 2014 final mortality statistics; July 1, 2014 population estimates based on the 2010 decennial census; and 2014 Medicare data for persons aged 66–99. The methodology used to estimate the life tables for the Hispanic population remains unchanged from the methodology developed for the publication of life tables by Hispanic origin for data year 2006. The methodology used to estimate the 2014 life tables for all other groups was first implemented with data year 2008. Results—In 2014, the overall expectation of life at birth was 78.9 years, a 0.1-year increase from 2013. Between 2013 and 2014, life expectancy at birth increased by 0.1 year for both males (76.4 to 76.5) and females (81.2 to 81.3) and for the black (75.5 to 75.6) and white (79.0 to 79.1) populations. Life expectancy at birth increased by 0.2 years for the Hispanic (81.9 to 82.1) and non-Hispanic black (75.1 to 75.3) populations. Life expectancy at birth remained unchanged for the non-Hispanic white population (78.8).},
author = {Arias, Elizabeth and Heron, Melonie and Xu, Jiaquan},
file = {:Users/fae/Documents/Mendeley Desktop/Arias, Heron, Xu/National Vital Statistics Reports/Arias, Heron, Xu - 2017 - United States Life Tables, 2014.pdf:pdf},
journal = {National Vital Statistics Reports},
keywords = {Hispanic origin,death rates,race,survival},
number = {4},
pages = {63},
title = {{United States Life Tables, 2014}},
url = {https://www.cdc.gov/nchs/data/nvsr/nvsr66/nvsr66{\_}04.pdf},
volume = {66},
year = {2017}
}
@article{Keiding1991,
author = {Keiding, Niels},
file = {:Users/fae/Documents/Mendeley Desktop/Keiding/Journal of the Royal Statistical Society. Series A (Statistics in Society)/Keiding - 1991 - Age-Specific Incidence and Prevalence A Statistical Perspective(2).pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series A (Statistics in Society)},
number = {3},
pages = {371--412},
title = {{Age-Specific Incidence and Prevalence: A Statistical Perspective}},
volume = {154},
year = {1991}
}
@incollection{Axler2005,
address = {New York, NY},
author = {Axler, S and Gehring, F W and Ribet, K A},
doi = {10.1007/0-387-27645-9},
isbn = {0-387-23233-8},
publisher = {Springer},
title = {{Difference Equations}},
url = {http://link.springer.com/10.1007/0-387-27645-9},
year = {2005}
}
@article{Cohen2017,
author = {Cohen, Joshua T and Neumann, Peter J and Wong, John B},
doi = {10.7326/0003},
file = {:Users/fae/Documents/Mendeley Desktop/Cohen, Neumann, Wong/Annals of Internal Medicine/Cohen, Neumann, Wong - 2017 - A Call for Open-Source Cost-Effectiveness Analysis.pdf:pdf},
journal = {Annals of Internal Medicine},
keywords = {Open source,cost-effectiveness analysis},
mendeley-tags = {Open source,cost-effectiveness analysis},
number = {6},
pages = {432--433},
title = {{A Call for Open-Source Cost-Effectiveness Analysis}},
volume = {167},
year = {2017}
}
@book{Hunink2014,
address = {Cambridge},
author = {Hunink, M.G. G. Myriam and Weinstein, Milton C. and Wittenberg, Eve and Drummond, Michael F. and Pliskin, Joseph S. and Wong, John B. and Glasziou, Paul P.},
doi = {10.1017/CBO9781139506779},
edition = {2},
file = {:Users/fae/Documents/Mendeley Desktop/Hunink et al/Unknown/Hunink et al. - 2014 - Decision Making in Health and Medicine.PDF:PDF},
isbn = {9781139506779},
publisher = {Cambridge University Press},
title = {{Decision Making in Health and Medicine}},
url = {http://ebooks.cambridge.org/ref/id/CBO9781139506779},
year = {2014}
}
@misc{InternationalSocietyforPharmacoeconomicsandOutcomesResearch2018,
author = {{International Society for Pharmacoeconomics and Outcomes Research}},
file = {:Users/fae/Documents/Mendeley Desktop/International Society for Pharmacoeconomics and Outcomes Research/Unknown/International Society for Pharmacoeconomics and Outcomes Research - 2018 - Health Outcomes Metrics Index of Open Source Code.pdf:pdf},
title = {{Health Outcomes Metrics Index of Open Source Code}},
url = {https://www.ispor.org/heor-resources/more-heor-resources/health-outcomes-metrics-index-of-open-source-code},
urldate = {2018-01-09},
year = {2018}
}
@article{Krijkamp2018a,
author = {Krijkamp, Eline and Alarid-Escudero, Fernando and Enns, Eva A and Hunink, Myriam G M and Pechlivanoglou, Petros and {Hawre Jalal}},
file = {:Users/fae/Documents/Mendeley Desktop/Krijkamp et al/Working Paper/Krijkamp et al. - 2018 - Retrieving epidemiological outcomes from state transition models using multidimensional matrices.pdf:pdf},
institution = {Erasmus MC},
journal = {Working Paper},
title = {{Retrieving epidemiological outcomes from state transition models using multidimensional matrices}},
year = {2018}
}
@book{Lee2003a,
address = {Hoboken, NJ},
author = {Lee, Elisa T. and Wang, John Wenyu},
edition = {3rd},
file = {:Users/fae/Documents/Mendeley Desktop/Lee, Wang/Unknown/Lee, Wang - 2003 - Statistical methods for Survival Data Analysis.pdf:pdf},
isbn = {3175723993},
publisher = {Wiley},
title = {{Statistical methods for Survival Data Analysis}},
year = {2003}
}
@article{Iskandar2018,
abstract = {Following its introduction over three decades ago, the cohort model has been used extensively to model population trajectories over time in decision-analytic modeling and health decision analysis studies. However, the stochastic process underlying cohort models has not been properly described. In this study, we explicate the stochastic process underlying a cohort model, by carefully formulating the dynamics of populations across health states and assigning probability rules on these dynamics. From this formulation, we explicate a mathematical representation of the system, which is given by the master equation: an evolution equation of the associated probability distribution. We solve the master equation by using the probability generation function method to obtain the explicit form of the probability of observing a particular realization of the system at an arbitrary time. The resulting generating function is used to derive the analytical expressions for calculating the mean and the variance of the process. Secondly, we represent the cohort model by a difference equation for the number of individuals across all states. From the difference equation, a continuous-time cohort model is recovered and takes the form of an ordinary differential equation. To show the equivalence between the derived stochastic process and the cohort model, we conduct a numerical exercise. We demonstrate that the population trajectories generated from the formulas match those from the cohort model simulation. In summary, the commonly-used cohort model represent the average of a continuous-time stochastic process on a multidimensional integer lattice governed by a master equation. Knowledge of the stochastic process underlying a cohort model provides a theoretical foundation for the modeling method.},
archivePrefix = {arXiv},
arxivId = {430173},
author = {Iskandar, Rowan},
doi = {10.1101/430173},
eprint = {430173},
file = {:Users/fae/Documents/Mendeley Desktop/Iskandar/bioRxiv/Iskandar - 2018 - A theoretical foundation of state-transition cohort models.pdf:pdf},
journal = {bioRxiv},
title = {{A theoretical foundation of state-transition cohort models}},
url = {https://www.biorxiv.org/content/early/2018/09/28/430173},
volume = {430173},
year = {2018}
}
@article{Jalal2017b,
abstract = {As the complexity of health decision science applications increases, high-level programming languages are increasingly adopted for statistical analyses and numerical computations. These programming languages facilitate sophisticated mod- eling, model documentation, and analysis reproducibility. Among the high-level programming languages, the statistical programming framework R is gaining increased recognition. R is freely available, cross-platform compatible, and open source. A large community of users who have generated an extensive collection of well-documented packages and func- tions supports it. These functions facilitate applications of health decision sciencemethodology as well as the visualiza- tion and communication of results. Although R's popularity is increasing among health decision scientists, methodologi- cal extensions of R in the field of decision analysis remain isolated. The purpose of this article is to provide an overview of existing R functionality that is applicable to the various stages of decision analysis, including model design, input parameter estimation, and analysis of model outputs.},
author = {Jalal, Hawre and Pechlivanoglou, Petros and Krijkamp, Eline and Alarid-Escudero, Fernando and Enns, Eva A. and Hunink, M. G. Myriam},
doi = {10.1177/0272989X16686559},
file = {:Users/fae/Documents/Mendeley Desktop/Jalal et al/Medical Decision Making/Jalal et al. - 2017 - An Overview of R in Health Decision Sciences.pdf:pdf},
issn = {0272-989X},
journal = {Medical Decision Making},
keywords = {Literature Review,R project,cost-effectiveness analysis,economic evaluation},
number = {7},
pages = {735--746},
title = {{An Overview of R in Health Decision Sciences}},
url = {http://journals.sagepub.com/doi/10.1177/0272989X16686559},
volume = {37},
year = {2017}
}
@incollection{Grimmett2014,
abstract = {A Markov chain is a process that moves from state to state in such a manner that the distribution of the next state depends on past states only through the current one. We show how to determine future probabilities for such a process, as well as its limiting probabilities and long run proportion of time it spends in any given state. Many examples of this process are given.},
author = {Grimmett, Geoffrey and Welsh, Dominic},
booktitle = {Probability: An Introduction},
chapter = {12},
edition = {2nd},
isbn = {9780198709978},
keywords = {Difference equations},
mendeley-tags = {Difference equations},
pages = {203--},
publisher = {Oxford University Press},
title = {{Markov Chains}},
url = {www.statslab.cam.ac.uk/{~}grg/teaching/chapter12.pdf},
year = {2014}
}
@book{Rothman2008h,
author = {Rothman, Kenneth J and Greenland, Sander and Lash, Timothy L.},
edition = {3rd},
editor = {Rothman, Kenneth J and Greenland, Sander and Lash, Timothy L.},
publisher = {Lippincott Williams {\&} Wilkins},
title = {{Modern Epidemiology}},
year = {2008}
}
@article{Poole2007,
author = {Poole, Chris and Agawal, Samir and Currie, Craig J},
doi = {10.1136/bmj.333.7558.61.3},
file = {:Users/fae/Documents/Mendeley Desktop/Poole, Agawal, Currie/British Medical Journal/Poole, Agawal, Currie - 2007 - Let cost effectiveness models be open to scrutiny.pdf:pdf},
issn = {09598146},
journal = {British Medical Journal},
number = {7623},
pages = {735},
pmid = {17932165},
title = {{Let cost effectiveness models be open to scrutiny}},
volume = {335},
year = {2007}
}
@article{Goldhaber-Fiebert2015a,
author = {Goldhaber-Fiebert, J. D. and Jalal, H. J.},
doi = {10.1177/0272989X15605091},
file = {:Users/fae/Documents/Mendeley Desktop/Goldhaber-Fiebert, Jalal/Medical Decision Making/Goldhaber-Fiebert, Jalal - 2015 - Some Health States Are Better Than Others Using Health State Rank Order to Improve Probabilistic An(2).pdf:pdf},
issn = {0272-989X},
journal = {Medical Decision Making},
number = {8},
title = {{Some Health States Are Better Than Others: Using Health State Rank Order to Improve Probabilistic Analyses. Supplement}},
url = {http://mdm.sagepub.com/cgi/doi/10.1177/0272989X15605091},
volume = {36},
year = {2015}
}
@article{Elbasha2016,
abstract = {Background. Modeling guidelines recommend applying a half-cycle correction (HCC) to outcomes from discrete-time state-transition models (DTSTMs). However, there is still no consensus on why and how to perform the correction. The objective was to provide theoretical foundations for HCC and to compare (both mathematically and numerically) the performance of different correction methods in reducing errors in outcomes from DTSTMs. Methods. We defined 7 methods from the field of numerical integration: Riemann sum of rectangles (left, midpoint, right), trapezoids, life-table, and Simpson's 1/3rd and 3/8th rules. We applied these methods to a standard 3-state disease progression Markov chain to evaluate the cost-effectiveness of a hypothetical intervention. We solved the discrete- and continuous-time (our gold standard) versions of the model analytically and derived expressions for various outcomes including discounted quality-adjusted life-years, discounted costs, and incremental cost-effectiveness ratios. Results. The standard HCC method gave the same results as the trapezoidal rule and life-table method. We found situations where applying the standard HCC can do more harm than good. Compared with the gold standard, all correction methods resulted in approximation errors. Contrary to conventional wisdom, the errors need not cancel each other out or become insignificant when incremental outcomes are calculated. We found that a wrong decision can be made with a less accurate method. The performance of each correction method vastly improved when a shorter cycle length was selected; Simpson's 1/3rd rule was the fastest method to converge to the gold standard. Conclusion. Cumulative outcomes in DTSTMs are prone to errors that can be reduced with more accurate methods like Simpson's rules. We clarified several misconceptions and provided recommendations and algorithms for practical implementation of these methods.},
author = {Elbasha, Elamin H. and Chhatwal, Jagpreet},
doi = {10.1177/0272989X15585121},
file = {:Users/fae/Documents/Mendeley Desktop/Elbasha, Chhatwal/Medical Decision Making/Elbasha, Chhatwal - 2016 - Theoretical foundations and practical applications of within-cycle correction methods.pdf:pdf},
issn = {1552681X},
journal = {Medical Decision Making},
keywords = {continuous time,discrete time,half-cycle correction,numerical integration,state-transition models},
number = {1},
pages = {115--131},
pmid = {26092831},
title = {{Theoretical foundations and practical applications of within-cycle correction methods}},
volume = {36},
year = {2016}
}
@article{Pershing2014,
author = {Pershing, Suzann and Enns, Eva A and Matesic, Brian and Owens, Douglas K and Goldhaber-Fiebert, Jeremy D},
doi = {10.7326/M13-0768},
file = {:Users/fae/Documents/Mendeley Desktop/Pershing et al/Annals of Internal Medicine/Pershing et al. - 2014 - Cost-Effectiveness of Treatment of Diabetic Macular Edema.pdf:pdf},
journal = {Annals of Internal Medicine},
number = {1},
pages = {18--29},
title = {{Cost-Effectiveness of Treatment of Diabetic Macular Edema}},
volume = {160},
year = {2014}
}
@article{Alarid-Escudero2020c,
abstract = {Clinical trials often report intervention efficacy in terms of the reduction in all-cause mortality between the treatment and control arms (i.e., an overall hazard ratio [oHR]) instead of the reduction in disease-specific mortality (i.e., a disease-specific hazard ratio [dsHR]). Using oHR to reduce all-cause mortality beyond the time horizon of the trial may introduce bias if the relative proportion of other-cause mortality increases with age. We sought to quantify this oHR extrapolation bias and propose a new approach to overcome this bias.},
author = {Alarid-Escudero, Fernando and Kuntz, Karen M},
doi = {10.1007/s40273-019-00859-5},
file = {:Users/fae/Documents/Mendeley Desktop/Alarid-Escudero, Kuntz/PharmacoEconomics/Alarid-Escudero, Kuntz - 2020 - Potential Bias Associated with Modeling the Effectiveness of Healthcare Interventions in Reducing Mor(2).pdf:pdf},
issn = {1179-2027},
journal = {PharmacoEconomics},
number = {3},
pages = {285--296},
title = {{Potential Bias Associated with Modeling the Effectiveness of Healthcare Interventions in Reducing Mortality Using an Overall Hazard Ratio. Supplement}},
url = {https://doi.org/10.1007/s40273-019-00859-5},
volume = {38},
year = {2020}
}
@article{Lu2018b,
abstract = {Introduction Anaplastic lymphoma kinase (ALK) rearrangement gene testing is used increasingly to identify patients with advanced non-small-cell lung cancer (NSCLC) who are most likely to benefit from crizotinib. This study was to evaluate the cost-effectiveness of the ALK tests followed by crizotinib compared to the standard chemotherapy in advanced NSCLC from the Chinese healthcare system perspective. Methods A 10-year Markov model was constructed to compare the costs and quality-adjusted lifeyears (QALYs) of crizotinib with standard chemotherapy, guided by the ALK rearrangement tests: next-generation sequencing (NGS) panel tests and multiplex polymerase chain reaction (PCR) testing. The health states included progression-free survival (PFS), progressed survival, and death. The costs examined included cost of drugs (pemetrexed, standard chemotherapy, salvage chemotherapy, and crizotinib), follow-up, palliative care, supportive care, severe adverse events, and ALK rearrangement testing. Results Under Patient Assistance Program (PAP), the model demonstrated that the patients using NGS panel tests spent US {\$}31,388 and gained 0.780 QALYs, whereas patients using multiplex PCR spent US {\$}31,362 and gained 0.780 QALYs, respectively. The incremental costeffectiveness ratios of crizotinib with PAP compared to the control strategy were projected at {\$}14,384 (NGS) and {\$}13,740 (multiplex PCR) per QALY gained, respectively. Sensitivity analyses showed the utility of PFS and the costs of crizotinib and pemetrexed were the most impactful factors on the model outcomes. The results were robust to changes in all parameters. Conclusion ALK-rearrangement test positive followed by crizotinib may be cost-effective compared to standard chemotherapy from the Chinese healthcare system perspective when PAP was available.},
author = {Lu, Shun and Yu, Yongfeng and Fu, Shijun and Ren, Hongye},
doi = {10.1371/journal.pone.0205827},
file = {:Users/fae/Documents/Mendeley Desktop/Lu et al/PLoS ONE/Lu et al. - 2018 - Cost-effectiveness of ALK testing and first-line crizotinib therapy for non-small-cell lung cancer in China.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
number = {10},
pages = {1--12},
title = {{Cost-effectiveness of ALK testing and first-line crizotinib therapy for non-small-cell lung cancer in China}},
volume = {13},
year = {2018}
}
@article{Elbasha2016a,
author = {Elbasha, Elamin H and Chhatwal, Jagpreet},
file = {:Users/fae/Documents/Mendeley Desktop/Elbasha, Chhatwal/PharmacoEconomics/Elbasha, Chhatwal - 2016 - Myths and misconceptions of within-cycle correction a guide for modelers and decision makers.pdf:pdf},
journal = {PharmacoEconomics},
number = {1},
pages = {13--22},
publisher = {Springer},
title = {{Myths and misconceptions of within-cycle correction: a guide for modelers and decision makers}},
volume = {34},
year = {2016}
}
@article{Iskandar2018a,
abstract = {Following its introduction over three decades ago, the cohort model has been used extensively to model population trajectories over time in decision-analytic modeling and health decision analysis studies. However, the stochastic process underlying cohort models has not been properly described. In this study, we explicate the stochastic process underlying a cohort model, by carefully formulating the dynamics of populations across health states and assigning probability rules on these dynamics. From this formulation, we explicate a mathematical representation of the system, which is given by the master equation: an evolution equation of the associated probability distribution. We solve the master equation by using the probability generation function method to obtain the explicit form of the probability of observing a particular realization of the system at an arbitrary time. The resulting generating function is used to derive the analytical expressions for calculating the mean and the variance of the process. Secondly, we represent the cohort model by a difference equation for the number of individuals across all states. From the difference equation, a continuous-time cohort model is recovered and takes the form of an ordinary differential equation. To show the equivalence between the derived stochastic process and the cohort model, we conduct a numerical exercise. We demonstrate that the population trajectories generated from the formulas match those from the cohort model simulation. In summary, the commonly-used cohort model represent the average of a continuous-time stochastic process on a multidimensional integer lattice governed by a master equation. Knowledge of the stochastic process underlying a cohort model provides a theoretical foundation for the modeling method.},
archivePrefix = {arXiv},
arxivId = {430173},
author = {Iskandar, Rowan},
doi = {10.1101/430173},
eprint = {430173},
file = {:Users/fae/Documents/Mendeley Desktop/Iskandar/PLOS ONE/Iskandar - 2018 - A theoretical foundation of state-transition cohort models in health decision analysis.pdf:pdf},
isbn = {1111111111},
journal = {PLOS ONE},
number = {12},
pages = {e0205543},
title = {{A theoretical foundation of state-transition cohort models in health decision analysis}},
url = {https://www.biorxiv.org/content/early/2018/09/28/430173},
volume = {13},
year = {2018}
}
@article{Hawkins2005,
abstract = {When constructing decision-analytic models to evaluate the cost-effectiveness of alternative treatments, we often need to extrapolate beyond the available experimental data, as these typically relate to a limited period starting from the initiation of a new treatment or the diagnosis of the current disease state. We may also be required to extrapolate beyond the available experimental evidence to compare potential treatment sequences. Markov models are often used for this extrapolation. These models have the defining assumption that future transition probabilities are independent of past transitions. This means that, in general, transition probabilities cannot be conditional of the time spent in a given state. Where data exist to show that the risks of transition are conditional on the time spent in the treatment state, the simplifying Markov assumption can result in a loss in the model's "face validity," and misleading results might be generated. Several methods are available to incorporate time dependency into transition probabilities based on standard methods and software. These include the inclusion of tunnel states in Markov models and patient-level simulation, where a series of individual patients are simulated. This article considers the features and limitations of these methods and also describes a novel approach to building time dependency into a Markov model by incorporating an additional time dimension resulting in a "semi-Markov" model. An example of the implementation of such a model, using the R statistical programming language, is illustrated using a cost-effectiveness model for new epilepsy therapies.},
author = {Hawkins, Neil and Sculpher, Mark and Epstein, David},
doi = {10.1177/0272989X05280562},
file = {:Users/fae/Documents/Mendeley Desktop/Hawkins, Sculpher, Epstein/Medical Decision Making/Hawkins, Sculpher, Epstein - 2005 - Cost-effectiveness analysis of treatments for chronic disease Using R to incorporate time dependency.pdf:pdf},
issn = {0272-989X},
journal = {Medical Decision Making},
keywords = {Chronic Disease,Chronic Disease: therapy,Cost-Benefit Analysis,Evidence-Based Medicine,Humans,Patient Simulation,Probability,Treatment Outcome},
number = {5},
pages = {511--9},
pmid = {16160207},
title = {{Cost-effectiveness analysis of treatments for chronic disease: Using R to incorporate time dependency of treatment response.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16160207},
volume = {25},
year = {2005}
}
@book{Kalbfleisch2002,
address = {Hoboken, NJ, USA},
author = {Kalbfleisch, John D. and Prentice, Ross L.},
edition = {Second},
file = {:Users/fae/Documents/Mendeley Desktop/Kalbfleisch, Prentice/Unknown/Kalbfleisch, Prentice - 2002 - The Statistical Analysis of Failure Time Data.pdf:pdf},
isbn = {3175723993},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{The Statistical Analysis of Failure Time Data}},
year = {2002}
}
@article{Caro2012,
abstract = {Models-mathematical frameworks that facilitate estimation of the consequences of health care decisions-have become essential tools for health technology assessment. Evolution of the methods since the first ISPOR modeling task force reported in 2003 has led to a new task force, jointly convened with the Society for Medical Decision Making, and this series of seven papers presents the updated recommendations for best practices in conceptualizing models; implementing state-transition approaches, discrete event simulations, or dynamic transmission models; dealing with uncertainty; and validating and reporting models transparently. This overview introduces the work of the task force, provides all the recommendations, and discusses some quandaries that require further elucidation. The audience for these papers includes those who build models, stakeholders who utilize their results, and, indeed, anyone concerned with the use of models to support decision making.},
author = {Caro, J Jaime and Briggs, Andrew H and Siebert, Uwe and Kuntz, Karen M},
doi = {10.1177/0272989X12454577},
file = {:Users/fae/Documents/Mendeley Desktop/Caro et al/Medical Decision Making/Caro et al. - 2012 - Modeling good research practices--overview A report of the ISPOR-SMDM Modeling Good Research Practices Task Force-1.pdf:pdf},
issn = {1552-681X},
journal = {Medical Decision Making},
keywords = {Biomedical Research,Delivery of Health Care,Delivery of Health Care: organization {\&} administra,Models,Theoretical,Uncertainty},
number = {5},
pages = {667--77},
pmid = {22990082},
title = {{Modeling good research practices--overview: A report of the ISPOR-SMDM Modeling Good Research Practices Task Force-1}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22990082},
volume = {32},
year = {2012}
}
@article{Djatche2018,
abstract = {Background: Suboptimal adherence to aspirin therapy for secondary prevention of cardiovascular (CV) events is an important public health problem. Prior studies have demonstrated non-adherent patients are at higher risk of experiencing CV events. Objectives: This study aimed to estimate the clinical and economic outcomes of aspirin non-adherence in patients with a prior primary CV event. Methods: We developed a Markov model to estimate the cost-effectiveness of aspirin adherence from a generic US managed care payer perspective over a 5-year time horizon. Costs, utilities and rates of aspirin adherence, CV events and adverse events were gathered from published literature to populate the model. Outcomes were quality-adjusted life years (QALYs), costs (US{\$}) and incremental cost-effectiveness ratios (ICERs). We applied the model separately to a population without type II diabetes as a comorbidity (non-diabetic model) and a population with type II diabetes (type II diabetes model). A one-way sensitivity analysis was performed to assess the model uncertainty. Results: The base case showed adherent patients lived 0.25 and 0.36 QALYs longer than non-adherent patients in the non-diabetic model and type II diabetes model, respectively. Adherence to aspirin had an ICER of US{\$}25/QALY in the non-diabetic population, while it saved US{\$}297 per patient over a 5-year period in the type II diabetes population. One-way sensitivity analysis showed the models were most sensitive to rates of non-fatal events in non-adherent patients. Conclusion: This study suggests aspirin adherence may improve QALYs for patients with a prior primary CV event. Further, it may decrease costs in patients with type II diabetes. While additional research is needed to validate these results, payers may wish to increase strategies to promote adherence in order to improve population health. Trial Registration: Not applicable.},
author = {Djatche, Laurence M. and Varga, Stefan and Lieberthal, Robert D.},
doi = {10.1007/s41669-018-0075-2},
file = {:Users/fae/Documents/Mendeley Desktop/Djatche, Varga, Lieberthal/PharmacoEconomics - Open/Djatche, Varga, Lieberthal - 2018 - Cost-Effectiveness of Aspirin Adherence for Secondary Prevention of Cardiovascular Events.pdf:pdf},
issn = {2509-4262},
journal = {PharmacoEconomics - Open},
number = {4},
pages = {371--380},
publisher = {Springer International Publishing},
title = {{Cost-Effectiveness of Aspirin Adherence for Secondary Prevention of Cardiovascular Events}},
url = {https://doi.org/10.1007/s41669-018-0075-2},
volume = {2},
year = {2018}
}
@article{Keiding1991a,
abstract = {In epidemiology incidence denotes the rate of occurrence of new cases (of disease), while prevalence is the frequency in the population (of diseased people). From a statistical point of view it is useful to understand incidence and prevalence in the parameter space, incidence as intensity (hazard) and prevalence as probability, and to relate observable quantities to these via a statistical model. In this paper such a framework is based on modelling each individual's dynamics in the Lexis diagram by a simple three-state stochastic process in the age direction and recruiting individuals from a Poisson process in the time direction. The resulting distributions in the cross-sectional population allow a rigorous discussion of the interplay between age-specific incidence and prevalence as well as of the statistical analysis of epidemiological cross-sectional data. For the latter, this paper focuses on methods from modern nonparametric continuous time survival analysis, including random censoring and truncation models and estimation under monotonicity constraints. The exposition is illustrated by examples, primarily from the author's epidemiological experience.},
author = {Keiding, Niels},
doi = {10.2307/2983150},
file = {:Users/fae/Documents/Mendeley Desktop/Keiding/Journal of the Royal Statistical Society. Series A (Statistics in Society)/Keiding - 1991 - Age-specific Incidence and Prevalence A Statistical Perspective.pdf:pdf},
isbn = {09641998},
issn = {09641998},
journal = {Journal of the Royal Statistical Society. Series A (Statistics in Society)},
keywords = {CENSORING,CURRENT STATUS DATA,DIABETES INCIDENCE,GRENANDER ESTI.MATOR: INCIDENCE: LEXIS DIAGRAJI: .,MENOPAUSE: MYASTHENZA GRA VZS,Non PARAMETRIC MAXIMUM LIKELIHOOD,POISSON PROCESS,PREVALENCE,SCREENING,TRANSMISSION POTENTIAL,TRUNCATION,VACCINATION},
number = {3},
pages = {371--412},
title = {{Age-specific Incidence and Prevalence: A Statistical Perspective}},
volume = {154},
year = {1991}
}
@article{Kalbfleisch1988,
abstract = {Data related to life histories of individuals can be obtained in many different ways, and the usefulness of multi-state models for statistical analysis is generally highly dependent on the type and nature of the data. In this paper, we focus on this, and present an approach to estimation for certain 'difficult' situations associated with retrospective or incomplete prospective observation. The paper begins with the identification of some problem areas in the analysis of data on life history processes. We discuss maximum likelihood estimation in some simple contexts and introduce a pseudo-likelihood which enables the simple analysis of some sampling procedures. This approach is illustrated on standard retrospective and case-cohort designs.},
author = {Kalbfleisch, John D. and Lawless, Jerald F.},
doi = {10.1002/sim.4780070116},
file = {:Users/fae/Documents/Mendeley Desktop/Kalbfleisch, Lawless/Statistics in medicine/Kalbfleisch, Lawless - 1988 - Likelihood analysis of multi-state models for disease incidence and mortality.pdf:pdf},
isbn = {0277-6715 (Print)$\backslash$r0277-6715 (Linking)},
issn = {0277-6715},
journal = {Statistics in medicine},
number = {1-2},
pages = {149--160},
pmid = {3353602},
title = {{Likelihood analysis of multi-state models for disease incidence and mortality.}},
volume = {7},
year = {1988}
}
@article{Smith-Spangler2010,
author = {Smith-Spangler, Crystal M. and Juusola, Jessie L. and Enns, Eva A. and Owens, Douglas K. and Garber, Alan M.},
doi = {10.7326/0003-4819-152-8-201004200-00212},
file = {:Users/fae/Documents/Mendeley Desktop/Smith-Spangler et al/Annals of Internal Medicine/Smith-Spangler et al. - 2010 - Population Strategies to Decrease Sodium Intake and the Burden of Cardiovascular Disease A Cost-Effective.pdf:pdf},
journal = {Annals of Internal Medicine},
number = {8},
pages = {481--487},
title = {{Population Strategies to Decrease Sodium Intake and the Burden of Cardiovascular Disease: A Cost-Effectiveness Analysis}},
url = {http://annals.org/article.aspx?articleid=745729},
volume = {152},
year = {2010}
}
@article{Gidwani2020,
abstract = {This tutorial presents practical guidance on transforming various typesof information published in journals, or available online from government and other sources, into transition probabilities for use in state-transition models, including cost-effectiveness models. Much, but not all, of the guidance has been previously published in peer-reviewed journals. Our purpose is to collect it in one location to serve as a stand-alone resource for decision modelers who draw most or all of their information from the published literature. Our focus is on the technical aspects of manipulating data to derive transition probabilities. We explain how to derive model transition probabilities from the following types of statistics: relative risks, odds, odds ratios, and rates. We then review the well-known approach for converting probabilities to match the model's cycle length when there are two health-state transitions and how to handle the case of three or more health-state transitions, for which the two-state approach is not appropriate. Other topics discussed include transition probabilities for population subgroups, issues to keep in mind when using data from different sources in the derivation process, and sensitivity analyses, including the use of sensitivity analysis to allocate analyst effort in refining transition probabilities and ways to handle sources of uncertainty that are not routinely formalized in models. The paper concludes with recommendations to help modelers make the best use of the published literature.},
author = {Gidwani, Risha and Russell, Louise B.},
doi = {10.1007/s40273-020-00937-z},
file = {:Users/fae/Documents/Mendeley Desktop/Gidwani, Russell/PharmacoEconomics/Gidwani, Russell - 2020 - Estimating Transition Probabilities from Published Evidence A Tutorial for Decision Modelers.pdf:pdf},
isbn = {0123456789},
issn = {11792027},
journal = {PharmacoEconomics},
number = {11},
pages = {1153--1164},
publisher = {Springer International Publishing},
title = {{Estimating Transition Probabilities from Published Evidence: A Tutorial for Decision Modelers}},
url = {https://doi.org/10.1007/s40273-020-00937-z},
volume = {38},
year = {2020}
}
@article{Enns2015e,
abstract = {BACKGROUND: To identify best-fitting input sets using model calibration, individual calibration target fits are often combined into a single goodness-of-fit (GOF) measure using a set of weights. Decisions in the calibration process, such as which weights to use, influence which sets of model inputs are identified as best-fitting, potentially leading to different health economic conclusions. We present an alternative approach to identifying best-fitting input sets based on the concept of Pareto-optimality. A set of model inputs is on the Pareto frontier if no other input set simultaneously fits all calibration targets as well or better. METHODS: We demonstrate the Pareto frontier approach in the calibration of 2 models: a simple, illustrative Markov model and a previously published cost-effectiveness model of transcatheter aortic valve replacement (TAVR). For each model, we compare the input sets on the Pareto frontier to an equal number of best-fitting input sets according to 2 possible weighted-sum GOF scoring systems, and we compare the health economic conclusions arising from these different definitions of best-fitting. RESULTS: For the simple model, outcomes evaluated over the best-fitting input sets according to the 2 weighted-sum GOF schemes were virtually nonoverlapping on the cost-effectiveness plane and resulted in very different incremental cost-effectiveness ratios ({\$}79,300 [95{\%} CI 72,500-87,600] v. {\$}139,700 [95{\%} CI 79,900-182,800] per quality-adjusted life-year [QALY] gained). Input sets on the Pareto frontier spanned both regions ({\$}79,000 [95{\%} CI 64,900-156,200] per QALY gained). The TAVR model yielded similar results. CONCLUSIONS: Choices in generating a summary GOF score may result in different health economic conclusions. The Pareto frontier approach eliminates the need to make these choices by using an intuitive and transparent notion of optimality as the basis for identifying best-fitting input sets.},
author = {Enns, Eva A and Cipriano, Lauren E and Simons, Cyrena T and Kong, Chung Yin},
doi = {10.1177/0272989X14528382},
file = {:Users/fae/Documents/Mendeley Desktop/Enns et al/Medical Decision Making/Enns et al. - 2015 - Identifying Best-Fitting Inputs in Health-Economic Model Calibration A Pareto Frontier Approach.pdf:pdf},
issn = {1552-681X},
journal = {Medical Decision Making},
number = {2},
pages = {170--182},
pmid = {24799456},
title = {{Identifying Best-Fitting Inputs in Health-Economic Model Calibration: A Pareto Frontier Approach}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24799456},
volume = {35},
year = {2015}
}
@article{Alarid-Escudero2020,
abstract = {Decision models can synthesize evidence from different sources to provide estimates of long-term consequences of a decision with uncertainty. Cohort state-transition models (cSTM) are decision models commonly used in medical decision making because they can simulate hypothetical cohorts' transitions across various health states over time. This tutorial shows how to conceptualize cSTMs in a programming language environment and shows examples of their implementation in R. We illustrate their use in a cost-effectiveness analysis of a treatment using a previously published testbed cSTM. Both time-independent cSTM where transition probabilities are constant over time and time-dependent cSTM where transition probabilities vary over time are represented. For the time-dependent cSTM, we consider transition probabilities dependent on age and state residence. We also illustrate how this setup can facilitate the computation of epidemiological outcomes of interest, such as survival and prevalence. We conclude by demonstrating how to calculate economic outcomes and conducting a cost-effectiveness analysis of a treatment compared to usual care using the testbed model. We provide a link to a public repository with all the R code described in this tutorial that can be used to replicate the example or to be modified to suit different decision modeling needs.},
archivePrefix = {arXiv},
arxivId = {2001.07824v1},
author = {Alarid-Escudero, Fernando and Krijkamp, Eline M. and Enns, Eva A. and Hunink, M. G. Myriam and Pechlivanoglou, Petros and Jalal, Hawre},
eprint = {2001.07824v1},
file = {:Users/fae/Documents/Mendeley Desktop/Alarid-Escudero et al/arXiv2001.07824v1/Alarid-Escudero et al. - 2020 - Cohort state-transition models in R From conceptualization to implementation.pdf:pdf},
journal = {arXiv:2001.07824v1},
pages = {1--31},
title = {{Cohort state-transition models in R: From conceptualization to implementation}},
url = {http://arxiv.org/abs/2001.07824},
year = {2020}
}
@book{Klein2003,
author = {Klein, John P. and Moeschberger, Melvin L.},
edition = {2nd},
file = {:Users/fae/Documents/Mendeley Desktop/Klein, Moeschberger/Unknown/Klein, Moeschberger - 2003 - Survival Analysis Techniques for Censored and Truncated Data.pdf:pdf},
isbn = {038795399X},
publisher = {Springer-Verlag},
title = {{Survival Analysis: Techniques for Censored and Truncated Data}},
url = {http://www.springer.com/statistics/life+sciences,+medicine+{\&}+health/book/978-0-387-95399-1},
year = {2003}
}
@article{Soares2012,
abstract = {The design of decision-analytic models for cost-effectiveness analysis has been the subject of discussion. The current work addresses this issue by noting that, when time is to be explicitly modelled, we need to represent phenomena occurring in continuous time. Models evaluated in continuous time may not have closed-form solutions, and in this case, two approximations can be used: simulation models in continuous time and discretized models at the aggregate level. Stylized examples were set up where both approximations could be implemented. These aimed to illustrate determinants of the use of the two approximations: cycle length and precision, the use of continuity corrections in discretized models and the discretization of rates into probabilities. The examples were also used to explore the impact of the approximations not only in terms of absolute survival but also cost effectiveness and incremental comparisons. Discretized models better approximate continuous time results if lower cycle lengths are used. Continuous time simulation models are inherently stochastic, and the precision of the results is determined by the simulation sample size. The use of continuity corrections in discretized models allows the use of greater cycle lengths, producing no significant bias from the discretization. How the process is discretized (the conversion of rates into probabilities) is key. Results show that appropriate discretization coupled with the use of a continuity correction produces results unbiased for higher cycle lengths. Alternative methods of discretization are less efficient, i.e. lower cycle lengths are needed to obtain unbiased results. The developed work showed the importance of acknowledging bias in estimating cost effectiveness. When the alternative approximations can be applied, we argue that it is preferable to implement a cohort discretized model rather than a simulation model in continuous time. In practice, however, it may not be possible to represent the decision problem by any conventionally defined discretized model, in which case other model designs need to be applied, e.g. a simulation model.},
author = {Soares, Marta O. and {Canto E Castro}, Lu{\'{i}}sa},
doi = {10.2165/11599380-000000000-00000},
file = {:Users/fae/Documents/Mendeley Desktop/Soares, Canto E Castro/PharmacoEconomics/Soares, Canto E Castro - 2012 - Continuous time simulation and discretized models for cost-effectiveness analysis.pdf:pdf},
issn = {11707690},
journal = {PharmacoEconomics},
keywords = {Cost-effectiveness,Cost-utility,Decision-analysis,Discrete-event- simulation,Markov-model,Modelling},
month = {dec},
number = {12},
pages = {1101--1117},
pmid = {23116289},
title = {{Continuous time simulation and discretized models for cost-effectiveness analysis}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23116289},
volume = {30},
year = {2012}
}
@article{Beck1983,
author = {Beck, J.Robert and Pauker, Stephen G.},
doi = {10.1177/0272989X8300300403},
file = {:Users/fae/Documents/Mendeley Desktop/Beck, Pauker/Medical Decision Making/Beck, Pauker - 1983 - The Markov process in medical prognosis.pdf:pdf},
issn = {0272-989X},
journal = {Medical Decision Making},
number = {4},
pages = {419--458},
title = {{The Markov process in medical prognosis}},
url = {http://mdm.sagepub.com/cgi/doi/10.1177/0272989X8300300403},
volume = {3},
year = {1983}
}
@article{Sathianathen2018a,
author = {Sathianathen, Niranjan J. and Konety, Badrinath R. and Alarid-Escudero, Fernando and Lawrentschuk, Nathan and Bolton, Damien M. and Kuntz, Karen M.},
doi = {10.1016/j.eururo.2018.10.055},
file = {:Users/fae/Documents/Mendeley Desktop/Sathianathen et al/European Urology/Sathianathen et al. - 2019 - Cost-effectiveness Analysis of Active Surveillance Strategies for Men with Low-risk Prostate Cancer.pdf:pdf},
issn = {03022838},
journal = {European Urology},
keywords = {conservative management},
number = {6},
pages = {910--917},
pmid = {30425010},
publisher = {European Association of Urology},
title = {{Cost-effectiveness Analysis of Active Surveillance Strategies for Men with Low-risk Prostate Cancer}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0302283818308534},
volume = {75},
year = {2019}
}
@article{Elbasha2016b,
author = {Elbasha, Elamin H and Chhatwal, Jagpreet},
file = {:Users/fae/Documents/Mendeley Desktop/Elbasha, Chhatwal/PharmacoEconomics/Elbasha, Chhatwal - 2016 - Myths and misconceptions of within-cycle correction a guide for modelers and decision makers. Supplement 1.pdf:pdf},
journal = {PharmacoEconomics},
number = {1},
pages = {1--6},
title = {{Myths and misconceptions of within-cycle correction: a guide for modelers and decision makers. Supplement 1}},
volume = {34},
year = {2016}
}
@misc{Jansen2017,
author = {Jansen, Jeroen P. and Incerti, Devin and Linthicum, Mark},
booktitle = {Health Affairs Blog},
doi = {10.1377/hblog20171212.640960},
file = {:Users/fae/Documents/Mendeley Desktop/Jansen, Incerti, Linthicum/Health Affairs Blog/Jansen, Incerti, Linthicum - 2017 - An Open-Source Consensus-Based Approach To Value Assessment.pdf:pdf},
month = {dec},
title = {{An Open-Source Consensus-Based Approach To Value Assessment}},
year = {2017}
}
@article{Elbasha,
author = {Elbasha, Elamin H and Chhatwal, Jagpreet},
file = {:Users/fae/Documents/Mendeley Desktop/Elbasha, Chhatwal/PharmacoEconomics/Elbasha, Chhatwal - 2016 - Myths and misconceptions of within-cycle correction a guide for modelers and decision makers. Supplement 2 E.xlsx:xlsx},
journal = {PharmacoEconomics},
number = {1},
title = {{Myths and misconceptions of within-cycle correction: a guide for modelers and decision makers. Supplement 2 Excel spreadsheet}},
volume = {34},
year = {2016}
}
@article{Jalal2017a,
author = {Jalal, Hawre and Pechlivanoglou, Petros and Krijkamp, Eline and Alarid-Escudero, Fernando and Enns, Eva A. and Hunink, M. G. Myriam},
file = {:Users/fae/Documents/Mendeley Desktop/Jalal et al/Medical Decision Making/Jalal et al. - 2017 - An Overview of R in Health Decision Sciences. Supplement.pdf:pdf},
isbn = {9780387773162},
journal = {Medical Decision Making},
number = {7},
title = {{An Overview of R in Health Decision Sciences. Supplement}},
volume = {37},
year = {2017}
}
@article{Sasieni2011,
abstract = {BACKGROUND: The 'lifetime risk' of cancer is generally estimated by combining current incidence rates with current all-cause mortality ('current probability' method) rather than by describing the experience of a birth cohort. As individuals may get more than one type of cancer, what is generally estimated is the average (mean) number of cancers over a lifetime. This is not the same as the probability of getting cancer.$\backslash$n$\backslash$nMETHODS: We describe a method for estimating lifetime risk that corrects for the inclusion of multiple primary cancers in the incidence rates routinely published by cancer registries. The new method applies cancer incidence rates to the estimated probability of being alive without a previous cancer. The new method is illustrated using data from the Scottish Cancer Registry and is compared with 'gold-standard' estimates that use (unpublished) data on first primaries.$\backslash$n$\backslash$nRESULTS: The effect of this correction is to make the estimated 'lifetime risk' smaller. The new estimates are extremely similar to those obtained using incidence based on first primaries. The usual 'current probability' method considerably overestimates the lifetime risk of all cancers combined, although the correction for any single cancer site is minimal.$\backslash$n$\backslash$nCONCLUSION: Estimation of the lifetime risk of cancer should either be based on first primaries or should use the new method.},
author = {Sasieni, P D and Shelton, J and Ormiston-Smith, N and Thomson, C S and Silcocks, P B},
doi = {10.1038/bjc.2011.250},
file = {:Users/fae/Documents/Mendeley Desktop/Sasieni et al/British Journal of Cancer/Sasieni et al. - 2011 - What is the lifetime risk of developing cancer the effect of adjusting for multiple primaries.pdf:pdf},
isbn = {1532-1827 (Electronic)$\backslash$r0007-0920 (Linking)},
issn = {1532-1827},
journal = {British Journal of Cancer},
keywords = {80 and over,Adolescent,Adult,Aged,Cause of Death,Child,Female,Humans,Incidence,Infant,Lifetime risk,Male,Mathematics,Middle Aged,Multiple Primary,Multiple Primary: epidemiology,Neoplasms,Neoplasms: epidemiology,Newborn,Preschool,Probability,Risk Assessment,Risk Assessment: methods,Sex Factors},
mendeley-tags = {Lifetime risk},
number = {3},
pages = {460--5},
pmid = {21772332},
publisher = {Nature Publishing Group},
title = {{What is the lifetime risk of developing cancer?: the effect of adjusting for multiple primaries.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3172907{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {105},
year = {2011}
}
@article{Feuer1993,
author = {Feuer, Eric J and Wun, Lap-ming and Boring, Catherine C and Dana, W and Timmel, Marilyn J and Tong, Tony},
file = {:Users/fae/Documents/Mendeley Desktop/Feuer et al/Journal of the National Cancer Institute/Feuer et al. - 1993 - The lifetime risk of developing breast cancer.pdf:pdf},
journal = {Journal of the National Cancer Institute},
number = {11},
title = {{The lifetime risk of developing breast cancer}},
volume = {85},
year = {1993}
}
@incollection{Kuntz2017,
abstract = {This is a new chapter and underscores recent advances in the field. Analysts typically face situations in which the data available about the costs and effects of different interventions come from disparate sources and often from studies for which analysts do not have access to primary data. Models fill in the gaps and help to structure analysts' thinking. They provide a framework for synthesizing data from disparate sources, allowing extrapolations beyond the time horizons of available data and to population subgroups and strategies not observed in studies. This chapter reviews the different types of decision models and their relative advantages and disadvantages. It also provides recommendations for model structure, output, evaluation of uncertainty, and validation.},
address = {New York, NY},
author = {Kuntz, Karen M. and Russell, Louise B. and Owens, Douglas K. and Sanders, Gillian D. and Trikalinos, Thomas A. and Salomon, Joshua A.},
booktitle = {Cost-Effectiveness in Health and Medicine},
chapter = {5},
edition = {Second},
editor = {Neumann, Peter J. and Sanders, Gillian D. and Russell, Louise B. and Siegel, Joanna E. and Ganiats, Theodore G.},
file = {:Users/fae/Documents/Mendeley Desktop/Kuntz et al/Cost-Effectiveness in Health and Medicine/Kuntz et al. - 2017 - Decision Models in Cost-Effectiveness Analysis.pdf:pdf},
keywords = {Calibration,Decision models},
mendeley-tags = {Calibration,Decision models},
pages = {105--136},
publisher = {Oxford University Press},
title = {{Decision Models in Cost-Effectiveness Analysis}},
year = {2017}
}
@article{Snowsill2019,
abstract = {Background. Health economic evaluations frequently include projections for lifetime costs and health effects using modeling frameworks such as Markov modeling or discrete event simulation (DES). Markov models typically cannot represent events whose risk is determined by the length of time spent in state (sojourn time) without the use of tunnel states. DES is very flexible but introduces Monte Carlo variation, which can significantly limit the complexity of model analyses. Methods. We present a new methodological framework for health economic modeling that is based on, and extends, the concept of moment-generating functions (MGFs) for time-to-event random variables. When future costs and health effects are discounted, MGFs can be used to very efficiently calculate the total discounted life-years spent in a series of health states. Competing risks are incorporated into the method. This method can also be used to calculate discounted costs and health effects when these payoffs are constant per unit time, one-off, or exponential with regard to time. MGFs are extended to additionally support costs and health effects which are polynomial with regard to time (as in a commonly used model of population norms for EQ-5D utility). Worked Example. A worked example is used to demonstrate the application of the new method in practice and to compare it with Markov modeling and DES. Results are compared in terms of convergence and accuracy, and computation times are compared. R code and an Excel workbook are provided. Conclusions. The MGF method can be applied to health economic evaluations in the place of Markov modeling or DES and has certain advantages over both.},
author = {Snowsill, Tristan},
doi = {10.1177/0272989X19860119},
file = {:Users/fae/Documents/Mendeley Desktop/Snowsill/Medical Decision Making/Snowsill - 2019 - A New Method for Model-Based Health Economic Evaluation Utilizing and Extending Moment-Generating Functions.pdf:pdf},
issn = {0272-989X},
journal = {Medical Decision Making},
keywords = {2018,2019,accepted,august 24,cohort analysis,date received,discrete event simulation,june 5,markov model,mathematical models are frequently,moment-generating function,semi-markov model,used in health eco-},
number = {5},
pages = {523--539},
title = {{A New Method for Model-Based Health Economic Evaluation Utilizing and Extending Moment-Generating Functions}},
url = {http://journals.sagepub.com/doi/10.1177/0272989X19860119},
volume = {39},
year = {2019}
}
@article{Briggs1998d,
abstract = {Markov models are often employed to represent stochastic processes, that is, random processes that evolve over time. In a healthcare context, Markov models are particularly suited to modelling chronic disease. In this article, we describe the use of Markov models for economic evaluation of healthcare interventions. The intuitive way in which Markov models can handle both costs and outcomes make them a powerful tool for economic evaluation modelling. The time component of Markov models can offer advantages of standard decision tree models, particularly with respect to discounting. This paper gives a comprehensive description of Markov modelling for economic evaluation, including a discussion of the assumptions on which the type of model is based, most notably the memoryless quality of Markov models often termed the ‘Markovian assumption'. A hypothetical example of a drug intervention to slow the progression of a chronic disease is employed to demonstrate the modelling technique and the possible methods of analysing Markov models are explored. Analysts should be aware of the limitations of Markov models, particularly the Markovian assumption, although the adept modeller will often find ways around this problem. [ABSTRACT FROM AUTHOR]},
author = {Briggs, A. and Sculpher, M.},
file = {:Users/fae/Documents/Mendeley Desktop/Briggs, Sculpher/PharmacoEconomics/Briggs, Sculpher - 1998 - Briggs An introduction to Markov modelling for economic evaluation.pdf:pdf},
issn = {1170-7690},
journal = {PharmacoEconomics},
keywords = {chronic diseases,decision making,economics,evaluation,markov processes,medical care},
number = {4},
pages = {397--409},
title = {{Briggs An introduction to Markov modelling for economic evaluation}},
volume = {13},
year = {1998}
}
@article{Frederix2013a,
abstract = {INTRODUCTION Dynamic processes in cost-effectiveness analysis (CEA) are typically described using cohort simulations, which can be implemented as Markov models, or alternatively using systems of ordinary differential equations (ODEs). In the field of CEA, simple and potentially inaccurate single-step algorithms are commonly used for solving ODEs, which can potentially induce bias, especially if an incorrect step size is used. The aims of this project were 1) to implement and demonstrate the use of a modern and well-established hybrid linear multistep ODE solver algorithm (LSODA) in the context of CEA using the statistical scripting language R and 2) to quantify bias in outcome for a case example CEA as generated by a commonly used single-step ODE solver algorithm. METHODS A previously published CEA comparing the adjuvant breast cancer therapies anastrozole and tamoxifen was used as a case example to implement the computational framework. A commonly used single-step algorithm was compared with the proposed multistep algorithm to quantify bias in the single-step method. RESULTS A framework implementing the multistep ODE solver LSODA was successfully developed. When a single-step ODE solver with step size of 1 year was used, incremental life-years gained was underestimated by 0.016 years (5.6{\%} relative error, RE) and {\pounds}158 (6.8{\%} RE) compared with the multistep method. CONCLUSION The framework was found suitable for the conduct of CEAs. We demonstrated how the use of single-step algorithms with insufficiently small step sizes causes unnecessary bias in outcomes measures of CEAs. Scripting languages such as R can further improve transparency, reproducibility, and overall integrity in the field of health economics.},
author = {Frederix, Gerardus W J and van Hasselt, Johan G C and Severens, Johan L and H{\"{o}}vels, Anke M and Huitema, Alwin D R and Raaijmakers, Jan A M and Schellens, Jan H M},
doi = {10.1177/0272989X13476763},
file = {:Users/fae/Documents/Mendeley Desktop/Frederix et al/Medical Decision Making/Frederix et al. - 2013 - Development of a framework for cohort simulation in cost-effectiveness analyses using a multistep ordinary d(2).pdf:pdf},
isbn = {1552-681X (Electronic)$\backslash$r0272-989X (Linking)},
issn = {1552-681X},
journal = {Medical Decision Making},
keywords = {Markov model,R,cohort simulation,cost-effectiveness analysis,tamoxifen},
number = {6},
pages = {780--92},
pmid = {23515213},
title = {{Development of a framework for cohort simulation in cost-effectiveness analyses using a multistep ordinary differential equation solver algorithm in R.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23515213},
volume = {33},
year = {2013}
}
@article{Siebert2012d,
author = {Siebert, Uwe and Alagoz, O. and Bayoumi, A. M. and Jahn, B. and Owens, D. K. and Cohen, D. J. and Kuntz, K. M.},
file = {:Users/fae/Documents/Mendeley Desktop/Siebert et al/Medical Decision Making/Siebert et al. - 2012 - State-Transition Modeling A Report of the ISPOR-SMDM Modeling Good Research Practices Task Force-3. Supplement.pdf:pdf},
journal = {Medical Decision Making},
number = {5},
title = {{State-Transition Modeling: A Report of the ISPOR-SMDM Modeling Good Research Practices Task Force-3. Supplement}},
volume = {32},
year = {2012}
}
@article{Brinks2015,
author = {Brinks, Ralph and Landwehr, Sandra},
doi = {10.1093/imammb/dqu024},
file = {:Users/fae/Documents/Mendeley Desktop/Brinks, Landwehr/Mathematical Medicine and Biology/Brinks, Landwehr - 2015 - A new relation between prevalence and incidence of a chronic disease.pdf:pdf},
issn = {14778602},
journal = {Mathematical Medicine and Biology},
keywords = {Chronic diseases,Compartment models,Dementia,Incidence,Mortality,Prevalence},
number = {4},
pages = {425--435},
pmid = {25576933},
title = {{A new relation between prevalence and incidence of a chronic disease}},
volume = {32},
year = {2015}
}
@article{Miller1994,
abstract = {Confusion regarding proper use of the terms rate and risk persists in the literature. This has implications for the proper modeling of prognosis and transition between health states in decision analysis and related techniques. The issue is complicated by the plethora of terms related to rate and risk. Although the suggestion to use the terms force and probability as substitutes for rate and risk has some appeal, the change in terminology by itself is unlikely to solve all the confusion or misuse of terms. This paper clarifies the proper definitions and estimations of rates and risks and suggests critical factors for the decision analyst to re- member when using, modeling, or interpreting transition rates and risks. Key words: decision models; rate; risk; force; probability; transitions. (Med},
author = {Miller, Douglas K. and Homan, Sharon M.},
doi = {10.1177/0272989X9401400107},
file = {:Users/fae/Documents/Mendeley Desktop/Miller, Homan/Medical Decision Making/Miller, Homan - 1994 - Determining Transition Probabilities Confusion and Suggestions.pdf:pdf},
issn = {0272-989X},
journal = {Medical Decision Making},
month = {feb},
number = {1},
pages = {52--58},
title = {{Determining Transition Probabilities: Confusion and Suggestions}},
url = {http://mdm.sagepub.com/cgi/doi/10.1177/0272989X9401400107},
volume = {14},
year = {1994}
}
@article{Fay2004,
abstract = {Fay, Pfeiffer, Cronin, Le, and Feuer (Statistics in Medicine 2003; 22; 1837-1848) developed a formula to calculate the age-conditional probability of developing a disease for the first time (ACPDvD) for a hypothetical cohort. The novelty of the formula of Fay et al (2003) is that one need not know the rates of first incidence of disease per person-years alive and disease-free, but may input the rates of first incidence per person-years alive only. Similarly the formula uses rates of death from disease and death from other causes per person-years alive. The rates per person-years alive are much easier to estimate than per person-years alive and disease-free. Fay et al (2003) used simple piecewise constant models for all three rate functions which have constant rates within each age group. In this paper, we detail a method for estimating rate functions which does not have jumps at the beginning of age groupings, and need not be constant within age groupings. We call this method the mid-age group joinpoint (MAJ) model for the rates. The drawback of the MAJ model is that numerical integration must be used to estimate the resulting ACPDvD. To increase computational speed, we offer a piecewise approximation to the MAJ model, which we call the piecewise mid-age group joinpoint (PMAJ) model. The PMAJ model for the rates input into the formula for ACPDvD described in Fay et al (2003) is the current method used in the freely available DevCan software made available by the National Cancer Institute.},
author = {Fay, Michael P},
doi = {10.1186/1478-7954-2-6},
file = {:Users/fae/Documents/Mendeley Desktop/Fay/Population Health Metrics/Fay - 2004 - Estimating age conditional probability of developing disease from surveillance data.pdf:pdf},
issn = {1478-7954},
journal = {Population Health Metrics},
number = {1},
pages = {6},
pmid = {15279675},
title = {{Estimating age conditional probability of developing disease from surveillance data.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=517510{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {2},
year = {2004}
}
@article{VanRosmalen2013,
abstract = {Markov models are a simple and powerful tool for analyzing the health and economic effects of health care interventions. These models are usually evaluated in discrete time using cohort analysis. The use of discrete time assumes that changes in health states occur only at the end of a cycle period. Discrete-time Markov models only approximate the process of disease progression, as clinical events typically occur in continuous time. The approximation can yield biased cost-effectiveness estimates for Markov models with long cycle periods and if no half-cycle correction is made. The purpose of this article is to present an overview of methods for evaluating Markov models in continuous time. These methods use mathematical results from stochastic process theory and control theory. The methods are illustrated using an applied example on the cost-effectiveness of antiviral therapy for chronic hepatitis B. The main result is a mathematical solution for the expected time spent in each state in a continuous-time Markov model. It is shown how this solution can account for age-dependent transition rates and discounting of costs and health effects, and how the concept of tunnel states can be used to account for transition rates that depend on the time spent in a state. The applied example shows that the continuous-time model yields more accurate results than the discrete-time model but does not require much computation time and is easily implemented. In conclusion, continuous-time Markov models are a feasible alternative to cohort analysis and can offer several theoretical and practical advantages.},
author = {van Rosmalen, Joost and Toy, Mehlika and O'Mahony, James F.},
doi = {10.1177/0272989X13487947},
file = {:Users/fae/Documents/Mendeley Desktop/van Rosmalen, Toy, O'Mahony/Medical Decision Making/van Rosmalen, Toy, O'Mahony - 2013 - A Mathematical Approach for Evaluating Markov Models in Continuous Time without Discrete-Event Simu.pdf:pdf},
issn = {0272-989X},
journal = {Medical Decision Making},
month = {may},
number = {6},
pages = {767--779},
title = {{A Mathematical Approach for Evaluating Markov Models in Continuous Time without Discrete-Event Simulation}},
url = {http://mdm.sagepub.com/cgi/doi/10.1177/0272989X13487947},
volume = {33},
year = {2013}
}
@article{Begun2013,
abstract = {OBJECTIVES: Markov chain models are frequently used to study the clinical course of chronic diseases. The aim of this article is to adopt statistical methods to describe the time dynamics of chronically ill patients when 2 kinds of data sets--fully and partially observable data are available.$\backslash$n$\backslash$nMODEL: We propose a 6-state continuous-time Markov chain model for the progression of chronic kidney disease (CKD), where little is known about the transitions between the disease stages. States 1 to 3 of the model correspond to stages III to V of chronic kidney disease in the Kidney Disease Outcomes Quality Initiative (KDOQI) CKD classification. States 4 and 5 relate to dialysis and transplantation (renal replacement therapy), respectively. Death is the (absorbing) state 6.$\backslash$n$\backslash$nMETHODS AND DATA: The model can be investigated and identified using Kolmogorov's forward equations and the methods of survival analysis. Age dependency, covariates in the form of the Cox regression, and unobservable risks of transition (frailties) can be included in the model. We applied our model to a data set consisting of all 2097 patients from all renal centers in a region in North Rhine-Westphalia (Germany) in 2005-2010.$\backslash$n$\backslash$nRESULTS: We compared transitions and relative risks to the few data published and found them to be reasonable. For example, patients with diabetes had a significantly higher risk for disease progression compared with patients without diabetes.$\backslash$n$\backslash$nCONCLUSIONS: In summary, modeling may help to quantify disease progression and its predictors when only partially observable prospective data are available.},
author = {Begun, Alexander and Icks, Andrea and Waldeyer, Regina and Landwehr, Sandra and Koch, Michael and Giani, Guido},
doi = {10.1177/0272989X12466731},
file = {:Users/fae/Documents/Mendeley Desktop/Begun et al/Medical Decision Making/Begun et al. - 2013 - Identification of a multistate continuous-time nonhomogeneous Markov chain model for patients with decreased renal.pdf:pdf},
isbn = {2113382644},
issn = {1552-681X},
journal = {Medical Decision Making},
keywords = {Aged,Chronic,Chronic: physiopathology,Female,Germany,Humans,Kidney,Kidney Failure,Kidney: physiopathology,Male,Markov Chains,Models,Theoretical},
number = {2},
pages = {298--306},
pmid = {23275452},
title = {{Identification of a multistate continuous-time nonhomogeneous Markov chain model for patients with decreased renal function.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23275452},
volume = {33},
year = {2013}
}
@article{Cao2016,
author = {Cao, Q. and Buskens, E. and Feenstra, T. and Jaarsma, T. and Hillege, H. and Postmus, D.},
doi = {10.1177/0272989X15593080},
file = {:Users/fae/Documents/Mendeley Desktop/Cao et al/Medical Decision Making/Cao et al. - 2016 - Continuous-Time Semi-Markov Models in Health Economic Decision Making An Illustrative Example in Heart Failure Disea.pdf:pdf},
issn = {0272-989X},
journal = {Medical Decision Making},
number = {1},
pages = {59--71},
title = {{Continuous-Time Semi-Markov Models in Health Economic Decision Making: An Illustrative Example in Heart Failure Disease Management}},
url = {http://mdm.sagepub.com/cgi/doi/10.1177/0272989X15593080},
volume = {36},
year = {2016}
}
@article{Briggs1998b,
abstract = {Markov models are often employed to represent stochastic processes, that is, random processes that evolve over time. In a healthcare context, Markov models are particularly suited to modelling chronic disease. In this article, we describe the use of Markov models for economic evaluation of healthcare interventions. The intuitive way in which Markov models can handle both costs and outcomes make them a powerful tool for economic evaluation modelling. The time com- ponent of Markov models can offer advantages of standard decision tree models, particularly with respect to discounting. This paper gives a comprehensive de- scription of Markov modelling for economic evaluation, including a discussion of the assumptions on which the type of model is based, most notably the memory- less quality of Markov models often termed the 'Markovian assumption'. A hy- pothetical example of a drug intervention to slow the progression of a chronic disease is employed to demonstrate the modelling technique and the possible methods of analysing Markov models are explored. Analysts should be aware of the limitations of Markov models, particularly the Markovian assumption, al- though the adept modeller will often find ways around this problem},
author = {Briggs, Andrew and Sculpher, Mark J.},
file = {:Users/fae/Documents/Mendeley Desktop/Briggs, Sculpher/PharmacoEconomics/Briggs, Sculpher - 1998 - An Introduction to Markov Modelling for Economic Evaluation.pdf:pdf},
journal = {PharmacoEconomics},
number = {4},
pages = {397--409},
title = {{An Introduction to Markov Modelling for Economic Evaluation}},
volume = {13},
year = {1998}
}
@article{Dunlop2017,
author = {Dunlop, William C. N. and Mason, Nicola and Kenworthy, James and Akehurst, Ron L.},
doi = {10.1007/s40273-016-0479-8},
file = {:Users/fae/Documents/Mendeley Desktop/Dunlop et al/PharmacoEconomics/Dunlop et al. - 2017 - Benefits, Challenges and Potential Strategies of Open Source Health Economic Models.pdf:pdf},
issn = {1170-7690},
journal = {PharmacoEconomics},
number = {1},
pages = {125--128},
publisher = {Springer International Publishing},
title = {{Benefits, Challenges and Potential Strategies of Open Source Health Economic Models}},
url = {http://link.springer.com/10.1007/s40273-016-0479-8},
volume = {35},
year = {2017}
}
@article{Goldberg1956,
author = {Goldberg, Irving D. and Levin, Morton L. and Gerhardt, Paul R. and Handy, Vincent H. and Cashman, Rita E.},
doi = {10.1093/oxfordjournals.aje.a112432},
file = {:Users/fae/Documents/Mendeley Desktop/Goldberg et al/Journal of the National Cancer Institute/Goldberg et al. - 1956 - The probability of developing cancer.pdf:pdf},
issn = {00029262},
journal = {Journal of the National Cancer Institute},
number = {2},
pages = {155--173},
pmid = {879160},
title = {{The probability of developing cancer}},
volume = {17},
year = {1956}
}
@article{Naimark2013a,
author = {Naimark, David M. J. and Kabboul, Nader N. and Krahn, Murray D.},
doi = {10.1177/0272989X13501558},
file = {:Users/fae/Documents/Mendeley Desktop/Naimark, Kabboul, Krahn/Medical Decision Making/Naimark, Kabboul, Krahn - 2013 - The Half-Cycle Correction Revisited Redemption of a Kludge.pdf:pdf},
issn = {0272-989X},
journal = {Medical Decision Making},
month = {sep},
number = {7},
pages = {961--970},
title = {{The Half-Cycle Correction Revisited: Redemption of a Kludge}},
url = {http://mdm.sagepub.com/cgi/doi/10.1177/0272989X13501558},
volume = {33},
year = {2013}
}
@incollection{Kuntz2001,
abstract = {To accompany the hugely successful 'Methods for Economic Evaluation of Health Care Programmes 2e', this book is a thorough and rigorous discussion of the methodological principles and recent advances in the rapidly advancing field of theory and practice of economic evaluation in health care. Written by an internationally acclaimed group of authors, the book provides an in-depth discussion of the latest theoretical economic evaluation, including the methods for measuring costs and outcomes, the collection of data alongside clinical studies, ways of handling uncertainty, discounting and issues relating to the transferability of economic data. It is an ideal book for those studying economic evaluation on postgraduate or professional courses in health economics of public health.},
address = {New York, NY},
author = {Kuntz, Karen M. and Weinstein, Milton C.},
booktitle = {Economic Evaluation in Health Care: Merging Theory with Practice},
chapter = {7},
edition = {2nd},
editor = {Drummond, Michael F. and McGuire, Alistair},
file = {:Users/fae/Documents/Mendeley Desktop/Kuntz, Weinstein/Economic Evaluation in Health Care Merging Theory with Practice/Kuntz, Weinstein - 2001 - Modelling in economic evaluation.pdf:pdf},
isbn = {0192631764, 9780192631763},
pages = {141--171},
publisher = {Oxford University Press},
title = {{Modelling in economic evaluation}},
year = {2001}
}
@article{Alarid-Escudero2019e,
abstract = {The use of open-source programming languages, such as R, in health decision sciences is growing and has the potential to facilitate model transparency, reproducibility, and shareability. However, realizing this potential can be challenging. Models are complex and primarily built to answer a research question, with model sharing and transparency relegated to being sec- ondary goals. Consequently, code is often neither well documented nor systematically organized in a comprehensible and shareable approach. Moreover, many decision modelers are not formally trained in computer programming and may lack good coding practices, further compounding the problem of model transparency. To address these challenges, we propose a high-level framework for model-based decision and cost-effectiveness analyses (CEA) in R. The proposed framework consists of a conceptual, modular structure and coding recommendations for the implementation of model-based decision analyses in R. This framework defines a set of common decision model elements divided into five components: (1) model inputs, (2) decision model implementation, (3) model calibration, (4) model validation, and (5) analysis. The first four components form the model development phase. The analysis component is the application of the fully developed decision model to answer the policy or the research question of interest, assess decision uncertainty, and/or to determine the value of future research through value of information (VOI) analysis. In this framework, we also make recommendations for good coding practices specific to decision modeling, such as file organization and variable naming conventions. We showcase the framework through a fully functional, testbed decision model, which is hosted on GitHub for free download and easy adaptation to other applications. The use of this framework in decision modeling will improve code readability and model sharing, paving the way to an ideal, open-source world. 1},
author = {Alarid-Escudero, Fernando and Krijkamp, Eline and Pechlivanoglou, Petros and Jalal, Hawre and Kao, Szu-Yu Zoe and Yang, Alan and Enns, Eva A.},
doi = {10.1007/s40273-019-00837-x},
file = {:Users/fae/Documents/Mendeley Desktop/Alarid-Escudero et al/PharmacoEconomics/Alarid-Escudero et al. - 2019 - A Need for Change! A Coding Framework for Improving Transparency in Decision Modeling(2).pdf:pdf},
isbn = {4027301900},
issn = {1179-2027},
journal = {PharmacoEconomics},
number = {11},
pages = {1329--1339},
publisher = {Springer International Publishing},
title = {{A Need for Change! A Coding Framework for Improving Transparency in Decision Modeling}},
url = {https://doi.org/10.1007/s40273-019-00837-x},
volume = {37},
year = {2019}
}
@article{Goldhaber-Fiebert2015,
author = {Goldhaber-Fiebert, J. D. and Jalal, H. J.},
doi = {10.1177/0272989X15605091},
file = {:Users/fae/Documents/Mendeley Desktop/Goldhaber-Fiebert, Jalal/Medical Decision Making/Goldhaber-Fiebert, Jalal - 2015 - Some Health States Are Better Than Others Using Health State Rank Order to Improve Probabilistic Analy.pdf:pdf},
issn = {0272-989X},
journal = {Medical Decision Making},
keywords = {bias,correlated param-,eters,expected,information,joint distribu-,med decis making xxxx,parameter correlation,probabilistic sensitivity analysis,tion,value of information,value of partial perfect,xx},
number = {8},
pages = {927--940},
title = {{Some Health States Are Better Than Others: Using Health State Rank Order to Improve Probabilistic Analyses}},
url = {http://mdm.sagepub.com/cgi/doi/10.1177/0272989X15605091},
volume = {36},
year = {2015}
}
@article{Hawkins2005a,
author = {Hawkins, Neil and Epstein, David and Drummond, Michael and Wilby, Jennifer and Kainth, Anita and Chadwick, David and Sculpher, Mark},
file = {:Users/fae/Documents/Mendeley Desktop/Hawkins et al/Medical Decision Making/Hawkins et al. - 2005 - Assessing the Cost-Effectiveness of New Pharmaceuticals in Epilepsy in Adults The Results of a Probabilistic Dec.pdf:pdf},
journal = {Medical Decision Making},
number = {5},
pages = {493--510},
title = {{Assessing the Cost-Effectiveness of New Pharmaceuticals in Epilepsy in Adults: The Results of a Probabilistic Decision Model}},
volume = {25},
year = {2005}
}
@article{Mar2008,
abstract = {OBJECTIVES: The objective is to develop a method for calculating the prevalence of stroke based on Markov models and to apply it to the assessment of the budget impact analysis of thrombolytic treatment.$\backslash$n$\backslash$nMETHODS: A Markov model was used to reproduce the natural history of stroke. The first step was to run the model to build the sojourn matrix from the initial population vector. The second step was to ascertain the number of individuals in the origin of each annual cohort. Finally, prevalence figures were obtained, validated, and used to calculate the impact of treatment with thrombolysis in 10{\%} of patients with stroke in the Basque Country as if thrombolysis had begun in 2000 and would continue to 2015.$\backslash$n$\backslash$nRESULTS: Stroke prevalence rates per 100,000 for the entire population are 898 for men and 686 for women, with a combined rate of 774 for men and women. Rates for stroke-related disability are 358 per 100,000 for men, 275 for women, and 309 for men and women combined. If 10{\%} of the stroke patients would have received thrombolytic treatment from 2000 to 2015, the number of disabled in 2015 would be reduced by 328, and the net savings for the Basque society (2,100,000 inhabitants) would be 1.7 million euro.$\backslash$n$\backslash$nCONCLUSIONS: The budget impact analysis of thrombolysis for stroke starting in 2000 shows a positive impact on the health budget because it saves costs after 2006 and produces a net benefit in health from the beginning of treatment.},
author = {Mar, Javier and Sainz-Ezkerra, Mar{\'{i}}a and Miranda-Serrano, Erika},
doi = {10.1177/0272989X07312720},
file = {:Users/fae/Documents/Mendeley Desktop/Mar, Sainz-Ezkerra, Miranda-Serrano/Medical Decision Making/Mar, Sainz-Ezkerra, Miranda-Serrano - 2008 - Calculation of prevalence with markov models Budget impact analysis of thrombolysis for str.pdf:pdf},
isbn = {0272-989X (Print)$\backslash$r0272-989X (Linking)},
issn = {0272989X},
journal = {Medical Decision Making},
keywords = {Budget impact,Markov models,Prevalence,Stroke,Thrombolysis.},
number = {4},
pages = {481--490},
pmid = {18349439},
title = {{Calculation of prevalence with markov models: Budget impact analysis of thrombolysis for stroke}},
volume = {28},
year = {2008}
}
@article{Briggs2012,
abstract = {A model's purpose is to inform medical decisions and health care resource allocation. Modelers employ quantitative methods to structure the clinical, epidemiological, and economic evidence base and gain qualitative insight to assist decision makers in making better decisions. From a policy perspective, the value of a model-based analysis lies not simply in its ability to generate a precise point estimate for a specific outcome but also in the systematic examination and responsible reporting of uncertainty surrounding this outcome and the ultimate decision being addressed. Different concepts relating to uncertainty in decision modeling are explored. Stochastic (first-order) uncertainty is distinguished from both parameter (second-order) uncertainty and from heterogeneity, with structural uncertainty relating to the model itself forming another level of uncertainty to consider. The article argues that the estimation of point estimates and uncertainty in parameters is part of a single process and explores the link between parameter uncertainty through to decision uncertainty and the relationship to value-of-information analysis. The article also makes extensive recommendations around the reporting of uncertainty, both in terms of deterministic sensitivity analysis techniques and probabilistic methods. Expected value of perfect information is argued to be the most appropriate presentational technique, alongside cost-effectiveness acceptability curves, for representing decision uncertainty from probabilistic analysis.},
author = {Briggs, Andrew H. and Weinstein, Milton C. and Fenwick, Elisabeth A. L. and Karnon, Jonathan and Sculpher, Mark J. and Paltiel, A. David},
doi = {10.1177/0272989X12458348},
file = {:Users/fae/Documents/Mendeley Desktop/Briggs et al/Medical Decision Making/Briggs et al. - 2012 - Model Parameter Estimation and Uncertainty Analysis A Report of the ISPOR-SMDM Modeling Good Research Practices T.pdf:pdf},
issn = {1552-681X},
journal = {Medical Decision Making},
keywords = {guidelines,heterogeneity,sensitivity analysis,uncertainty analysis,value of information},
month = {sep},
number = {5},
pages = {722--732},
pmid = {22990087},
title = {{Model Parameter Estimation and Uncertainty Analysis: A Report of the ISPOR-SMDM Modeling Good Research Practices Task Force Working Group-6.}},
volume = {32},
year = {2012}
}
@article{Smith-Spangler2012,
abstract = {Decision modeling and cost effectiveness analysis have become important tools to inform clinical decision making and policy development, playing roles in policy decisions for human immunodeficiency virus1,2 and breast and colon cancer screening,3,4 as well as clinical decisions in the prevention of cardiac disease,5,6 for example. The establishment and use of best practices for model development, validation, and reporting are key steps in ensuring that model users have information they can trust.},
author = {Smith-Spangler, Crystal M.},
doi = {10.1177/0272989X12458977},
file = {:Users/fae/Documents/Mendeley Desktop/Smith-Spangler/Medical Decision Making/Smith-Spangler - 2012 - Transparency and reproducible research in modeling Why we need it and how to get there.pdf:pdf},
isbn = {1552-681X (Electronic)
0272-989X (Linking)},
issn = {0272989X},
journal = {Medical Decision Making},
number = {5},
pages = {663--666},
pmid = {22990081},
title = {{Transparency and reproducible research in modeling: Why we need it and how to get there}},
volume = {32},
year = {2012}
}
@article{Alarid-Escudero2019,
author = {Alarid-Escudero, Fernando and Enns, Eva A. and Kuntz, Karen M. and Michaud, Tzeyu L. and Jalal, Hawre},
doi = {10.1016/j.jval.2019.02.008},
file = {:Users/fae/Documents/Mendeley Desktop/Alarid-Escudero et al/Value in Health/Alarid-Escudero et al. - 2019 - Time Traveling Is Just Too Dangerous But Some Methods Are Worth Revisiting The Advantages of Expected Lo.pdf:pdf;:Users/fae/Documents/Mendeley Desktop/Alarid-Escudero et al/Value in Health/Alarid-Escudero et al. - 2019 - Time Traveling Is Just Too Dangerous But Some Methods Are Worth Revisiting The Advantages of Expected(2).pdf:pdf;:Users/fae/Documents/Mendeley Desktop/Alarid-Escudero et al/Value in Health/Alarid-Escudero et al. - 2019 - Time Traveling Is Just Too Dangerous But Some Methods Are Worth Revisiting The Advantages of Expected(2).pdf:pdf;:Users/fae/Documents/Mendeley Desktop/Alarid-Escudero et al/Value in Health/Alarid-Escudero et al. - 2019 - Time Traveling Is Just Too Dangerous But Some Methods Are Worth Revisiting The Advantages of Expected(5).pdf:pdf},
journal = {Value in Health},
keywords = {Cost-effectiveness acceptability curve (CEAC),Cost-effectiveness acceptability frontier (CEAF),Expected value of perfect information (EVPI),cost-effectiveness analysis,expected losse,probabilistic sensitivity analysis,unertainty analysis},
number = {5},
pages = {611--618},
title = {{"Time Traveling Is Just Too Dangerous" But Some Methods Are Worth Revisiting: The Advantages of Expected Loss Curves Over Cost-Effectiveness Acceptability Curves and Frontier}},
volume = {22},
year = {2019}
}
@article{Krijkamp2019,
abstract = {Cost-effectiveness analyses often rely on cohort state-transition models (cSTMs). The cohort trace is the primary outcome of cSTMs, which captures the proportion of the cohort in each health state over time (state occupancy). However, the cohort trace is an aggregated measure that does not capture the information about the specific transitions among the health states (transition dynamics). In practice, these transition dynamics are crucial in many applications, such as incorporating transition rewards or computing various epidemiological outcomes that could be used for model calibration and validation (e.g. disease incidence and lifetime risk). In this manuscript we propose modifying the transitional cSTMs cohort trace computation to compute and store cSTMs dynamics that capture both state occupancy and transition dynamics. This approach produces a multidimensional matrix from which both the state occupancy and the transition dynamics can be recovered. We highlight the advantages and potential applications of this approach with an example coded in R to facilitate the implementation of our method.},
author = {Krijkamp, Eline M. and Alarid-Escudero, Fernando and Enns, Eva and Pechlivanoglou, Petros and Hunink, MG Myriam and Jalal, Hawre},
file = {:Users/fae/Documents/Mendeley Desktop/Krijkamp et al/Medical Decision Making/Krijkamp et al. - 2019 - A Multidimensional Array Representation of State-Transition Model Dynamics.pdf:pdf;:Users/fae/Documents/Mendeley Desktop/Krijkamp et al/Medical Decision Making/Krijkamp et al. - 2019 - A Multidimensional Array Representation of State-Transition Model Dynamics(2).pdf:pdf},
journal = {Medical Decision Making},
title = {{A Multidimensional Array Representation of State-Transition Model Dynamics}},
volume = {In Press},
year = {2019}
}
@article{Krijkamp2018,
abstract = {{\textcopyright} 2018, {\textcopyright} The Author(s) 2018. Microsimulation models are becoming increasingly common in the field of decision modeling for health. Because microsimulation models are computationally more demanding than traditional Markov cohort models, the use of computer programming languages in their development has become more common. R is a programming language that has gained recognition within the field of decision modeling. It has the capacity to perform microsimulation models more efficiently than software commonly used for decision modeling, incorporate statistical analyses within decision models, and produce more transparent models and reproducible results. However, no clear guidance for the implementation of microsimulation models in R exists. In this tutorial, we provide a step-by-step guide to build microsimulation models in R and illustrate the use of this guide on a simple, but transferable, hypothetical decision problem. We guide the reader through the necessary steps and provide generic R code that is flexible and can be adapted for other models. We also show how this code can be extended to address more complex model structures and provide an efficient microsimulation approach that relies on vectorization solutions.},
author = {Krijkamp, Eline M. and Alarid-Escudero, Fernando and Enns, Eva A. and Jalal, Hawre J. and Hunink, M. G. Myriam and Pechlivanoglou, Petros},
doi = {10.1177/0272989X18754513},
file = {:Users/fae/Documents/Mendeley Desktop/Krijkamp et al/Medical Decision Making/Krijkamp et al. - 2018 - Microsimulation Modeling for Health Decision Sciences Using R A Tutorial.pdf:pdf;:Users/fae/Documents/Mendeley Desktop/Krijkamp et al/Medical Decision Making/Krijkamp et al. - 2018 - Microsimulation Modeling for Health Decision Sciences Using R A Tutorial.pdf:pdf},
isbn = {2059348242},
issn = {0272-989X},
journal = {Medical Decision Making},
keywords = {Markov model,R project,decision-analytic modeling,microsimulation,open source software},
month = {apr},
number = {3},
pages = {400--422},
pmid = {25869851},
title = {{Microsimulation Modeling for Health Decision Sciences Using R: A Tutorial}},
url = {http://journals.sagepub.com/doi/10.1177/0272989X18754513},
volume = {38},
year = {2018}
}
@article{Zdeb1977,
author = {Zdeb, Michael S.},
file = {:Users/fae/Documents/Mendeley Desktop/Zdeb/American Journal of Epidemiology/Zdeb - 1977 - The probability of developing cancer.pdf:pdf},
journal = {American Journal of Epidemiology},
number = {1},
pages = {6--16},
title = {{The probability of developing cancer}},
volume = {106},
year = {1977}
}

@article{Alarid-Escudero2021a,
author = {Alarid-Escudero, Fernando and Krijkamp, Eline and Enns, Eva A. and Yang, Alan and Hunink, M.G. G. Myriam and Pechlivanoglou, Petros and Jalal, Hawre},
mendeley-groups = {WorkingPapers/CohortModelsR},
title = {{An Introductory Tutorial to Cohort State-Transition Models in R}},
year = {2021}
}

@article{Alarid-Escudero2021b,
author = {Alarid-Escudero, Fernando and Krijkamp, Eline and Enns, Eva A. and Yang, Alan and Hunink, M.G. G. Myriam and Pechlivanoglou, Petros and Jalal, Hawre},
mendeley-groups = {WorkingPapers/CohortModelsR},
title = {{A Tutorial on Time-Dependent Cohort State-Transition Models in R}},
year = {2021}
}

@misc{Alarid-Escudero2021,
author = {Alarid-Escudero, Fernando and Easterly, Caleb A. and Knowlton, Greg and Enns, Eva A.},
mendeley-groups = {R},
title = {{dampack: Decision-Analytic Modeling Package}},
url = {https://cran.r-project.org/web/packages/dampack/ https://github.com/DARTH-git/dampack},
year = {2021}
}

@article{Briggs2002,
abstract = {When choosing between mutually exclusive treatment op- tions, it is common to construct a cost-effectiveness frontier on the cost-effectiveness plane that represents efficient points from among the treatment choices. Treatment options internal to the frontier are considered inefficient and are ex- cluded either by strict dominance or by appealing to the prin- ciple of extended dominance. However, when uncertainty is considered, options excluded under the baseline analysis mayform part of the cost-effectiveness frontier.Byadopting a Bayesian approach, where distributions for model parame- ters are specified, uncertainty in the decision concerning which treatment option should be implemented is addressed directly. The approach is illustrated using an example from a recently published cost-effectiveness analysis of different possible treatment strategies for gastroesophageal reflux dis- ease. It is argued that probabilistic analyses should be en- couraged because theyhavepotential to quantify the strength of evidence in favor of particular treatment choices. Key words: economic evaluation; probabilistic sensitivity analy- sis; Bayesian methods; uncertainty; simulation.},
author = {Briggs, Andrew H. and Goeree, Ron and Blackhouse, Gord and O'Brien, Bernie J.},
doi = {10.1177/027298902400448867},
file = {:Users/fae/Documents/Mendeley Desktop/Briggs et al/Medical Decision Making/Briggs et al. - 2002 - Probabilistic Analysis of Cost-Effectiveness Models Choosing between Treatment Strategies for Gastroesophageal(2).pdf:pdf},
issn = {00000000},
journal = {Medical Decision Making},
mendeley-groups = {Prelims/Dec Sci Prelim/Reflecting Uncertainty in CEAs,2ndSemester/PUBH{\_}6809{\_}AdvDecAnal,WorkingPapers/UQ-EMEWS},
month = {jul},
number = {4},
pages = {290--308},
title = {{Probabilistic Analysis of Cost-Effectiveness Models: Choosing between Treatment Strategies for Gastroesophageal Reflux Disease}},
url = {http://mdm.sagepub.com/cgi/doi/10.1177/027298902400448867},
volume = {22},
year = {2002}
}
